%\documentclass[11pt,leqno]{book}
%\usepackage[spanish,activeacute]{babel}
%\usepackage[utf8]{inputenc}
%\usepackage{enumerate}
%\usepackage{float}
%\usepackage{gensymb}
%
%\begin{document}


\chapter{Introducción}
\pagenumbering{arabic}
\setcounter{page}{1}

\section{Contextualización}
La reducción de dimensión se ha convertido, desde hace unos años, en uno de los grandes problemas de la informática, al almacenarse cada vez más información y tener que trabajar con grandes cantidades de datos, lo que conlleva tiempos de ejecución inabarcables, haciéndose muchas veces necesario eliminar partes de la información para poder trabajar con ella. Una de las formas de reducir la dimensión de un conjunto de datos es el análisis de componentes principales. A grandes rasgos, si se dispone de un conjunto de datos de $n$ dimensiones, el análisis de componentes principales busca $m$ nuevos ejes, rotación de los originales, con $m \leq n$, de forma que los datos representados en los nuevos ejes tienen sólo $m$ dimensiones. El número de ejes, es decir, de componentes principales, $m$, se puede elegir en función de la cantidad de información que se está dispuesto a perder, ya que se pueden ir eliminando aquellas componentes que menos influyan en los datos. Intuitivamente, cuanto más relacionados estén los datos entre sí, menos componentes principales serán necesarias. Esto es fácil de ver con el siguiente ejemplo: supongamos que disponemos de 10 datos en $\mathbb{R}^2$, todos alineados. Si obtenemos la primera componente principal, que será la línea por la que pasan los datos, y nos quedamos con la representación de los datos en esta línea, sólo tendremos que almacenar una dimensión, y además lo estamos haciendo sin perder información alguna.\\

Ahora, una de las formas en las que se almacena mucha información es cuando se guarda el valor de una variable a lo largo de periodos de tiempo, por ejemplo, la cantidad de lluvia en una ciudad a lo largo del año, el número de coches vendidos por meses a lo largo de los últimos 15, 20 o 30 años, el número de defunciones en una ciudad o país desde 1900, o la cantidad de contagios de enfermedades al mes por ciudades. Las posibilidades son infinitas y almacenar y trabajar sobre este tipo de información nos ayuda a predecir qué puede pasar sobre un determinado tema a corto plazo. Además, normalmente este tipo de información no es independiente y depende de varios factores. Por ejemplo, el número de defunciones dependerá del número de contagios de distintas enfermedades en la misma ciudad en ese mes, o el consumo de carburante con la cantidad de coches en circulación. Este tipo de información almacenada se llaman series temporales y es de nuevo interesante reducir la dimensión de las mismas con objeto de trabajar mejor sobre ellas. En esto se centra el paper de Daniel Peña y Víctor Yohai, \cite{pena16}, que aquí se aborda y del que se dan varias posibles aplicaciones.


\section{Descripción del problema abordado}
El problema abordado en este trabajo ha sido de iniciación a la investigación, en concreto, partir de un paper de relativa novedad (el de Peña y Yohai en \cite{pena16}, que aún no está publicado), entenderlo y buscar y documentarme primero en los cimientos en los que está basado (análisis de componentes principales y series temporales) para poder más tarde trabajar sobre él. Se ha hecho un estudio sobre los tiempos de cómputo del algoritmo dado en \cite{pena16} gracias a la versión del paquete de \texttt{R} en desarrollo facilitada por Daniel Peña y más tarde a la última versión llevada a cabo por Ezequiel Smucler cuya dirección se encuentra en \cite{ezeq}, debido a varios fallos en la versión previa. Se han llevado a cabo también varias posibles aplicaciones de este algoritmo, como compresión de imágenes en escala de grises y en color y buscar patrones en series temporales periódicas, además de predicción de nuevos valores de un conjunto de series temporales a través de la predicción en el conjunto de componentes principales dinámicas, facilitando y haciendo más rápida la predicción.

Se exponen aquí tanto el desarrollo teórico seguido para la comprensión del artículo como los resultados obtenidos de las pruebas y aplicaciones realizadas. Cabe señalar que todo el estudio práctico se ha hecho a través del software libre para análisis estadístico \texttt{R}, a excepción de los tests ANOVA y rangos múltiples, que se han hecho en una versión de prueba de Statgraphics.


\section{Técnicas y herramientas utilizadas}
Por un lado, los principales conceptos y técnicas matemáticas usadas en este proyecto han sido:
\begin{itemize}
\item Estadística: esperanza, varianza, covarianza y correlación.
\item Álgebra: matrices y simetría.
\item Geometría: formas cuadráticas, vectores propios, valores propios.
\item Análisis: técnica de los multiplicadores de Lagrange.
\end{itemize}
\textit{ }\\
Por otro lado, las principales áreas y técnicas informáticas utilizadas han sido:
\begin{itemize}
\item Algoritmia: comprensión de algoritmos utilizados por las herramientas usadas.
\item Programación funcional.
\item Automatización de pruebas ejecutables en cualquier máquina con el software de \texttt{R} necesario.
\item Aprendizaje automático:
\end{itemize}


\section{Contenido de la memoria}
En el capítulo~\ref{ch:introMates} se recogen los conceptos, técnicas y resultados matemáticos que van a ser necesarios para el resto de capítulos, tales como el concepto de varianza, el concepto de autocovarianza de orden $k$, el teorema de Lagrange para la técnica de los multiplicadores de Lagrange o el resultado sobre derivación de una forma cuadrática, entre otros.\\

En el capítulo~\ref{ch:matematicas} se expone la parte matemática del trabajo. En este capítulo se hace un estudio formal sobre el análisis de componentes principales, explicando cómo se obtienen las primeras componentes y por qué y dando después un método iterativo para obtener las demás. Además, se da una introducción a series temporales y se hace un resumen del método dado en \cite{pena16} para obtener las componentes principales dinámicas, recalcando las diferencias con el análisis de componentes principales original.\\

En el capítulo~\ref{ch:informatica} se llevan a cabo las tres aplicaciones realizadas sobre el algoritmo GDPC: compresión de imágenes, utilizando tanto imágenes en escala de grises como a color, búsqueda de patrones en series periódicas y predicción de un conjunto de series temporales a través de las componentes principales dinámicas.\\

En el capítulo \ref{ch:conclusiones} se exponen las conclusiones a las que se han llegado y las posibles vías futuras interesantes de tomar.\\


\section{Principales fuentes consultadas}
Las principales fuentes consultadas son el artículo de Peña y Yohai en \cite{pena16}, el libro de estadística multivariante \cite{anderson} y los apuntes de Ramón Sánchez, profesor de la UGR, \cite{sanchez}, para análisis de componentes principales y el libro \cite{pena05} para series temporales. El resto de fuentes se detallan en la bibliografía en la página \pageref{bibliography}.


%\end{document}